{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52dc9b17-1182-44b3-bebf-ae2f508675d3",
   "metadata": {},
   "source": [
    "# Handling Large Multi-Modal Payloads in AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how Amazon Bedrock AgentCore Runtime handles large payloads up to 100MB, including multi-modal content such as Excel files and images. AgentCore Runtime is designed to process rich media content and large datasets seamlessly.\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "|Information| Details|\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Large Payload & Multi-Modal Processing|\n",
    "| Agent type          | Single         |\n",
    "| Agentic Framework   | Strands Agents |\n",
    "| LLM model           | Anthropic Claude Sonnet 3.7 |\n",
    "| Tutorial components | Large File Processing, Image Analysis, Excel Data Processing |\n",
    "| Tutorial vertical   | Data Analysis & Multi-Modal AI                                                   |\n",
    "| Example complexity  | Intermediate                                                                     |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK|\n",
    "\n",
    "### Key Features\n",
    "\n",
    "* **Large Payload Support**: Process files up to 100MB in size\n",
    "* **Multi-Modal Processing**: Handle Excel files, images, and text simultaneously\n",
    "* **Data Analysis**: Extract insights from structured data and visual content\n",
    "* **Base64 Encoding**: Secure transmission of binary data through JSON payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Python 3.10+\n",
    "* AWS credentials configured\n",
    "* Docker running\n",
    "* Sample Excel file and image for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Create Sample Data Files\n",
    "\n",
    "Let's create sample Excel and image files to demonstrate large payload handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "create-sample-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file size: 0.05 MB\n",
      "Image file size: 0.01 MB\n",
      "Total payload size: 0.05 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Create a large Excel file with sample sales data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Date': pd.date_range('2023-01-01', periods=1000, freq='h'),\n",
    "    'Product': np.random.choice(['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y'], 1000),\n",
    "    'Sales': np.random.randint(1, 1000, 1000),\n",
    "    'Revenue': np.random.uniform(10.0, 5000.0, 1000),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 1000),\n",
    "    'Customer_ID': np.random.randint(1000, 9999, 1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('large_sales_data.xlsx', index=False)\n",
    "\n",
    "# Create a sample chart image\n",
    "img = Image.new('RGB', (600, 500), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Draw a simple bar chart\n",
    "products = ['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y']\n",
    "values = [250, 180, 320, 150, 280]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "\n",
    "max_value = max(values)\n",
    "bar_width = 120\n",
    "start_x = 100\n",
    "\n",
    "for i, (product, value, color) in enumerate(zip(products, values, colors)):\n",
    "    x = start_x + i * (bar_width + 20)\n",
    "    height = int((value / max_value) * 400)\n",
    "    y = 500 - height\n",
    "    \n",
    "    # Draw bar\n",
    "    draw.rectangle([x, y, x + bar_width, 500], fill=color)\n",
    "    \n",
    "    # Add labels (simplified without font)\n",
    "    draw.text((x + 10, 510), product[:8], fill='black')\n",
    "    draw.text((x + 10, y - 20), str(value), fill='black')\n",
    "\n",
    "draw.text((300, 50), 'Sales Performance by Product', fill='black')\n",
    "img.save('sales_chart.png')\n",
    "\n",
    "# Check file sizes\n",
    "excel_size = os.path.getsize('large_sales_data.xlsx') / (1024 * 1024)  # MB\n",
    "image_size = os.path.getsize('sales_chart.png') / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"Excel file size: {excel_size:.2f} MB\")\n",
    "print(f\"Image file size: {image_size:.2f} MB\")\n",
    "print(f\"Total payload size: {excel_size + image_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-code",
   "metadata": {},
   "source": [
    "## Create Multi-Modal Agent\n",
    "\n",
    "Let's create an agent that can process both Excel files and images from large payloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing multimodal_data_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multimodal_data_agent.py\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Initialize the model and agent\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    "    max_tokens=16000\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"\n",
    "    You are a data analysis assistant that can process large Excel files and images.\n",
    "    When given multi-modal data, analyze both the structured data and visual content,\n",
    "    then provide comprehensive insights combining both data sources.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def multimodal_data_processor(payload, context):\n",
    "    \"\"\"\n",
    "    Process large multi-modal payloads containing Excel data and images.\n",
    "    \n",
    "    Args:\n",
    "        payload: Contains prompt, excel_data (base64), image_data (base64)\n",
    "        context: Runtime context information\n",
    "    \n",
    "    Returns:\n",
    "        str: Analysis results from both data sources\n",
    "    \"\"\"\n",
    "    prompt = payload.get(\"prompt\", \"Analyze the provided data.\")\n",
    "    excel_data = payload.get(\"excel_data\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    print(f\"=== Large Payload Processing ===\")\n",
    "    print(f\"Session ID: {context.session_id}\")\n",
    "    \n",
    "    if excel_data:\n",
    "        print(f\"Excel data size: {len(excel_data) / 1024 / 1024:.2f} MB\")\n",
    "    if image_data:\n",
    "        print(f\"Image data size: {len(image_data) / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"Excel data {excel_data}\")\n",
    "    print(f\"Image data {image_data}\")\n",
    "    print(f\"=== Processing Started ===\")\n",
    "    # Decode base64 to bytes\n",
    "    excel_bytes = base64.b64decode(excel_data)\n",
    "    # Decode base64 to bytes\n",
    "    image_bytes = base64.b64decode(image_data)\n",
    "    \n",
    "    # Enhanced prompt with data context\n",
    "    enhanced_prompt = f\"\"\"{prompt}\n",
    "    Please analyze both data sources and provide insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = agent(\n",
    "        [{\n",
    "            \"document\": {\n",
    "                \"format\": \"xlsx\",\n",
    "                \"name\": \"excel_data\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": excel_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": image_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"text\": enhanced_prompt\n",
    "        }]\n",
    "    )\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-infrastructure",
   "metadata": {},
   "source": [
    "## Setup Infrastructure and Deploy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/Users/ykhvainitski/repos/bedrock-strands/ac_runtime_data_analysis/multimodal_data_agent.py, bedrock_agentcore_name=multimodal_data_agent\n",
      "Configuring BedrockAgentCore agent: multimodal_data_agent\n",
      "Generated Dockerfile: /Users/ykhvainitski/repos/bedrock-strands/ac_runtime_data_analysis/Dockerfile\n",
      "Generated .dockerignore: /Users/ykhvainitski/repos/bedrock-strands/ac_runtime_data_analysis/.dockerignore\n",
      "Keeping 'multimodal_data_agent' as default agent\n",
      "Bedrock AgentCore configured: /Users/ykhvainitski/repos/bedrock-strands/ac_runtime_data_analysis/.bedrock_agentcore.yaml\n"
     ]
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"multimodal_data_agent.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=\"multimodal_data_agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d117a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   ‚Ä¢ Build ARM64 containers in the cloud with CodeBuild\n",
      "   ‚Ä¢ No local Docker required\n",
      "üí° Available deployment modes:\n",
      "   ‚Ä¢ runtime.launch()                           ‚Üí CodeBuild (current)\n",
      "   ‚Ä¢ runtime.launch(local=True)                 ‚Üí Local development\n",
      "   ‚Ä¢ runtime.launch(local_build=True)           ‚Üí Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'multimodal_data_agent' to account 538213298977 (us-east-1)\n",
      "Starting CodeBuild ARM64 deployment for agent 'multimodal_data_agent' to account 538213298977 (us-east-1)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: multimodal_data_agent\n",
      "‚úÖ ECR repository available: 538213298977.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-multimodal_data_agent\n",
      "Getting or creating execution role for agent: multimodal_data_agent\n",
      "Using AWS region: us-east-1, account ID: 538213298977\n",
      "Role name: AmazonBedrockAgentCoreSDKRuntime-us-east-1-069e2d958e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reusing existing ECR repository: 538213298977.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-multimodal_data_agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚úÖ Reusing existing execution role: arn:aws:iam::538213298977:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-069e2d958e\n",
      "‚úÖ Execution role available: arn:aws:iam::538213298977:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-069e2d958e\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: multimodal_data_agent\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-069e2d958e\n",
      "Reusing existing CodeBuild execution role: arn:aws:iam::538213298977:role/AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-069e2d958e\n",
      "Using .dockerignore with 44 patterns\n",
      "Uploaded source to S3: multimodal_data_agent/20250828-184630.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-multimodal_data_agent-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "üîÑ QUEUED started (total: 0s)\n",
      "‚úÖ QUEUED completed in 5.2s\n",
      "üîÑ PROVISIONING started (total: 5s)\n",
      "‚úÖ PROVISIONING completed in 5.2s\n",
      "üîÑ DOWNLOAD_SOURCE started (total: 11s)\n",
      "‚úÖ DOWNLOAD_SOURCE completed in 5.2s\n",
      "üîÑ PRE_BUILD started (total: 16s)\n",
      "‚úÖ PRE_BUILD completed in 5.2s\n",
      "üîÑ BUILD started (total: 21s)\n",
      "‚úÖ BUILD completed in 72.5s\n",
      "üîÑ POST_BUILD started (total: 93s)\n",
      "‚úÖ POST_BUILD completed in 15.7s\n",
      "üîÑ COMPLETED started (total: 109s)\n",
      "‚úÖ COMPLETED completed in 0.0s\n",
      "üéâ CodeBuild completed successfully in 1m 49s\n",
      "CodeBuild completed successfully\n",
      "‚úÖ CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "‚ö†Ô∏è Session ID will be reset to connect to the updated agent. The previous agent remains accessible via the original session ID: c3899fb7-c882-4366-a10c-057020c70f5d\n",
      "‚úÖ Agent created/updated: arn:aws:bedrock-agentcore:us-east-1:538213298977:runtime/multimodal_data_agent-AlPLKT63c4\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-east-1:538213298977:runtime/multimodal_data_agent-AlPLKT63c4/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-east-1:538213298977:runtime/multimodal_data_agent-AlPLKT63c4\n",
      "Built with CodeBuild: bedrock-agentcore-multimodal_data_agent-builder:307807f8-2539-4fac-bbee-35fcef891ad1\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-east-1:538213298977:runtime/multimodal_data_agent-AlPLKT63c4\n",
      "ECR image: 538213298977.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-multimodal_data_agent\n",
      "üîç Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/multimodal_data_agent-AlPLKT63c4-DEFAULT\n",
      "   /aws/bedrock-agentcore/runtimes/multimodal_data_agent-AlPLKT63c4-DEFAULT/runtime-logs\n",
      "üí° Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/multimodal_data_agent-AlPLKT63c4-DEFAULT --follow\n",
      "üí° Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/multimodal_data_agent-AlPLKT63c4-DEFAULT --since 1h\n"
     ]
    }
   ],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wait-for-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: multimodal_data_agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final status: READY\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(f\"Deployment status: {status}\")\n",
    "\n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-large-payloads",
   "metadata": {},
   "source": [
    "## Test Large Multi-Modal Payloads\n",
    "\n",
    "Now let's test the agent with large payloads containing both Excel data and images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invoking BedrockAgentCore agent 'multimodal_data_agent' via cloud endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Processing large multi-modal payload...\n",
      "üìã Session ID: 06df269e-263c-4c5e-a721-77c9672f67ac\n",
      "üìÑ Excel size: 0.06 MB\n",
      "üñºÔ∏è Image size: 0.01 MB\n",
      "üì¶ Total payload: 0.07 MB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Sales Data Analysis\n",
       "\n",
       "## Overview of the Dataset\n",
       "\n",
       "I've analyzed your sales data from January 2023 to February 2023, which contains 1,000 records with hourly sales data for different products across various regions. The dataset includes information on product types (Gadget X, Gadget Y, Widget A, Widget B, Widget C), sales quantities, revenue, regions (East, West, North, South), and customer IDs.\n",
       "\n",
       "## Product Performance Analysis\n",
       "\n",
       "Looking at the chart image and correlating it with the Excel data:\n",
       "\n",
       "1. **Product Sales Distribution**:\n",
       "   - The chart shows four product categories with different sales volumes\n",
       "   - The blue bar (tallest) appears to represent approximately 320 units\n",
       "   - The coral/red bar shows around 250 units\n",
       "   - The teal bar shows about 180 units\n",
       "   - The light green bar shows approximately 150 units\n",
       "\n",
       "2. **Excel Data Product Analysis**:\n",
       "   - **Gadget X**: Total sales of 48,979 units (24.5% of total sales)\n",
       "   - **Gadget Y**: Total sales of 41,399 units (20.7% of total sales)\n",
       "   - **Widget A**: Total sales of 36,597 units (18.3% of total sales)\n",
       "   - **Widget B**: Total sales of 36,726 units (18.4% of total sales)\n",
       "   - **Widget C**: Total sales of 36,162 units (18.1% of total sales)\n",
       "\n",
       "## Regional Performance\n",
       "\n",
       "Based on the Excel data:\n",
       "\n",
       "1. **Sales by Region**:\n",
       "   - **North**: 51,735 units (25.9%)\n",
       "   - **East**: 50,531 units (25.3%)\n",
       "   - **South**: 49,479 units (24.7%)\n",
       "   - **West**: 48,118 units (24.1%)\n",
       "\n",
       "   This shows a relatively even distribution across all regions with North performing slightly better.\n",
       "\n",
       "2. **Revenue by Region**:\n",
       "   - **North**: $673,458,457 (26.6%)\n",
       "   - **East**: $633,948,036 (25.1%)\n",
       "   - **West**: $631,281,314 (25.0%)\n",
       "   - **South**: $590,005,015 (23.3%)\n",
       "\n",
       "   The North region generates the highest revenue despite only having a slight lead in unit sales.\n",
       "\n",
       "## Time-Based Analysis\n",
       "\n",
       "1. **Daily Sales Trends**:\n",
       "   - Average daily sales: 6,449 units\n",
       "   - Highest sales day: January 10 (7,136 units)\n",
       "   - Lowest sales day: January 1 (5,237 units)\n",
       "\n",
       "2. **Hourly Patterns**:\n",
       "   - Peak sales hours: 9:00-11:00 AM and 4:00-6:00 PM\n",
       "   - Lowest sales hours: 2:00-4:00 AM\n",
       "\n",
       "## Price and Revenue Analysis\n",
       "\n",
       "1. **Average Revenue per Unit**:\n",
       "   - **Widget C**: $2,379 per unit (highest)\n",
       "   - **Widget A**: $2,330 per unit\n",
       "   - **Widget B**: $2,276 per unit\n",
       "   - **Gadget Y**: $2,267 per unit\n",
       "   - **Gadget X**: $2,206 per unit (lowest)\n",
       "\n",
       "2. **Total Revenue by Product**:\n",
       "   - **Gadget X**: $108,065,116 (21.4%)\n",
       "   - **Widget C**: $86,032,257 (17.1%)\n",
       "   - **Widget A**: $85,273,309 (16.9%)\n",
       "   - **Widget B**: $83,586,083 (16.6%)\n",
       "   - **Gadget Y**: $93,862,435 (18.6%)\n",
       "\n",
       "## Key Insights\n",
       "\n",
       "1. **Product Performance**: Gadget X is the highest-selling product by volume (as shown in the chart's blue bar), but Widget C generates more revenue per unit.\n",
       "\n",
       "2. **Regional Balance**: The sales distribution across regions is fairly balanced, with North leading by a small margin. This suggests effective market penetration across all territories.\n",
       "\n",
       "3. **Price Optimization Opportunity**: There's an inverse relationship between unit price and sales volume for some products. For example, Widget C has the highest revenue per unit but lower overall sales volume.\n",
       "\n",
       "4. **Revenue vs. Volume**: While Gadget X leads in sales volume, its revenue per unit is the lowest, suggesting potential for price optimization to increase overall profitability.\n",
       "\n",
       "5. **Time Patterns**: The data shows clear daily and hourly sales patterns that could be leveraged for targeted marketing campaigns or inventory management.\n",
       "\n",
       "## Recommendations\n",
       "\n",
       "1. **Product Strategy**: Consider increasing marketing for Widget C in regions where it performs best, as it offers the highest revenue per unit.\n",
       "\n",
       "2. **Pricing Review**: Analyze the pricing strategy for Gadget X to potentially increase margins without significantly affecting sales volume.\n",
       "\n",
       "3. **Regional Focus**: While regions are performing relatively evenly, the North region generates higher revenue per sale, suggesting potential for premium product positioning in this market.\n",
       "\n",
       "4. **Time-Based Marketing**: Align marketing efforts with peak sales hours (9:00-11:00 AM and 4:00-6:00 PM) to maximize impact.\n",
       "\n",
       "5. **Customer Segmentation**: Analyze high-value customers (those purchasing high-margin products) to identify common characteristics for targeted marketing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import uuid\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Encode files to base64\n",
    "with open('large_sales_data.xlsx', 'rb') as f:\n",
    "    excel_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "with open('sales_chart.png', 'rb') as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# Create large payload\n",
    "large_payload = {\n",
    "    \"prompt\": \"Analyze the sales data from the Excel file and correlate it with the chart image. Provide insights on sales performance and trends.\",\n",
    "    \"excel_data\": excel_base64,\n",
    "    \"image_data\": image_base64\n",
    "}\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "print(f\"üìä Processing large multi-modal payload...\")\n",
    "print(f\"üìã Session ID: {session_id}\")\n",
    "print(f\"üìÑ Excel size: {len(excel_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"üñºÔ∏è Image size: {len(image_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"üì¶ Total payload: {len(json.dumps(large_payload)) / 1024 / 1024:.2f} MB\\n\")\n",
    "\n",
    "# Invoke agent with large payload\n",
    "invoke_response = agentcore_runtime.invoke(\n",
    "    large_payload,\n",
    "    session_id=session_id\n",
    ")\n",
    "final_response = \"\"\n",
    "for r in invoke_response['response']:\n",
    "    final_response += r.decode(\"utf-8\")\n",
    "response_data = json.loads(final_response)\n",
    "display(Markdown(response_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cleanup-resources",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleanup completed!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Clean up AWS resources\n",
    "agentcore_control_client = boto3.client('bedrock-agentcore-control', region_name=region)\n",
    "ecr_client = boto3.client('ecr', region_name=region)\n",
    "\n",
    "# Delete AgentCore Runtime\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "# Delete ECR repository\n",
    "ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# Clean up local files\n",
    "# os.remove('large_sales_data.xlsx')\n",
    "# os.remove('sales_chart.png')\n",
    "\n",
    "print(\"‚úÖ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have successfully demonstrated handling large multi-modal payloads with Amazon Bedrock AgentCore Runtime!\n",
    "\n",
    "## What you've learned:\n",
    "\n",
    "### Large Payload Processing\n",
    "* **100MB Support**: AgentCore Runtime can handle payloads up to 100MB\n",
    "* **Base64 Encoding**: Secure transmission of binary data through JSON payloads\n",
    "* **Efficient Processing**: Runtime optimized for large data processing\n",
    "\n",
    "### Multi-Modal Capabilities\n",
    "* **Excel Analysis**: Processing structured data from spreadsheets\n",
    "* **Image Processing**: Analyzing visual content and charts\n",
    "* **Combined Analysis**: Correlating insights from multiple data types\n",
    "\n",
    "### Key Benefits\n",
    "* **Rich Data Processing**: Handle complex, multi-format datasets\n",
    "* **Scalable Architecture**: Runtime designed for large workloads\n",
    "* **Tool Integration**: Custom tools for specialized data processing\n",
    "* **Enterprise Ready**: Secure handling of sensitive business data\n",
    "\n",
    "This demonstrates AgentCore Runtime's capability to handle enterprise-scale data processing tasks with multiple data modalities, making it ideal for complex business intelligence and data analysis applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
